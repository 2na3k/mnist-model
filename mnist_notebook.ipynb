{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, List\n",
    "from collections import deque\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.optim import Optimizer\n",
    "\n",
    "import numpy as np\n",
    "from torch import Tensor\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.modules.loss import _Loss\n",
    "\n",
    "from layers import Layer, Dense\n",
    "from model import Model\n",
    "from train import Trainer\n",
    "from utils import assert_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLayer(Layer):\n",
    "    def __init__(self, \n",
    "                 in_channels: int,\n",
    "                 out_channels: int,\n",
    "                 filter_size: int,\n",
    "                 activation: nn.Module = None,\n",
    "                 dropout: float = 1.0,\n",
    "                 flatten: bool = False) -> None:\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, filter_size, padding=filter_size // 2)\n",
    "        self.activation = activation\n",
    "        self.flatten = flatten\n",
    "        if dropout < 1: \n",
    "            self.dropout = nn.Dropout(1 - dropout)\n",
    "        \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = self.conv()\n",
    "        if self.activation:\n",
    "            x = self.activation(x)\n",
    "        \n",
    "        if self.flatten: \n",
    "            x = x.view(x.shape[0], x_shape[1] * x_shape[2] * x_shape[3])\n",
    "\n",
    "        if hasattr(self, \"dropout\"):\n",
    "            x = self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## De-convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeconvLayer(Layer):\n",
    "    def __init__(self,\n",
    "                 in_channels: int,\n",
    "                 out_channels: int,\n",
    "                 filter_size: int,\n",
    "                 activation: nn.Module = None,\n",
    "                 dropout: float = 1.0,\n",
    "                 flatten: bool = False) -> None:\n",
    "        super().__init__()\n",
    "        self.deconv = nn.ConvTranspose2d(in_channels, out_channels, filter_size, \n",
    "                                       padding=filter_size // 2)\n",
    "        self.activation = activation\n",
    "        self.flatten = flatten\n",
    "        if dropout < 1.0:\n",
    "            self.dropout = nn.Dropout(1 - dropout)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "\n",
    "        x = self.deconv(x)\n",
    "        if self.activation:\n",
    "            x = self.activation(x)\n",
    "        if self.flatten:\n",
    "            x = x.view(x.shape[0], x.shape[1] * x.shape[2] * x.shape[3])\n",
    "        if hasattr(self, \"dropout\"):\n",
    "            x = self.dropout(x)            \n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto-encoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder model\n",
    "class Autoencoder(Model):\n",
    "    def __init__(self,\n",
    "                 hidden_dim: int = 28):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.conv1 = ConvLayer(1, 14, 5, activation=nn.Tanh())\n",
    "        self.conv2 = ConvLayer(14, 7, 5, activation=nn.Tanh(), flatten=True)\n",
    "        \n",
    "        self.dense1 = Dense(7 * 28 * 28, hidden_dim, activation=nn.Tanh())\n",
    "        self.dense2 = Dense(hidden_dim, 7 * 28 * 28, activation=nn.Tanh())\n",
    "        \n",
    "        self.conv3 = ConvLayer(7, 14, 5, activation=nn.Tanh()) \n",
    "        self.conv4 = ConvLayer(14, 1, 5, activation=nn.Tanh())         \n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        assert_dim(x, 4)\n",
    "            \n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        \n",
    "        encoding = self.dense1(x)\n",
    "        \n",
    "        x = self.dense2(encoding)\n",
    "        \n",
    "        x = x.view(-1, 7, 28, 28)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "\n",
    "        return x, encoding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "img_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1305,), (0.3081,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MNIST(root='../mnist_data/',\n",
    "                      train=True, \n",
    "                      download=True,\n",
    "                      transform=img_transforms)\n",
    "\n",
    "test_dataset = MNIST(root='../mnist_data/',\n",
    "                     train=False, \n",
    "                     download=True,\n",
    "                     transform=img_transforms)\n",
    "\n",
    "mnist_train = ((train_dataset.data.type(torch.float32).unsqueeze(3).permute(0, 3, 1, 2) / 255.0) - 0.1305) / 0.3081\n",
    "mnist_test = ((test_dataset.data.type(torch.float32).unsqueeze(3).permute(0, 3, 1, 2) / 255.0) - 0.1305) / 0.3081"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/mnt/e/workspace/python/mnist-model/mnist_notebook.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/e/workspace/python/mnist-model/mnist_notebook.ipynb#ch0000012vscode-remote?line=1'>2</a>\u001b[0m criterion \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mMSELoss()\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/e/workspace/python/mnist-model/mnist_notebook.ipynb#ch0000012vscode-remote?line=2'>3</a>\u001b[0m optimizer \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39mSGD(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m0.01\u001b[39m, momentum\u001b[39m=\u001b[39m\u001b[39m0.9\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/e/workspace/python/mnist-model/mnist_notebook.ipynb#ch0000012vscode-remote?line=4'>5</a>\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(model, optimizer, criterion)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/e/workspace/python/mnist-model/mnist_notebook.ipynb#ch0000012vscode-remote?line=6'>7</a>\u001b[0m trainer\u001b[39m.\u001b[39mfit(X_train_auto, X_train_auto,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/e/workspace/python/mnist-model/mnist_notebook.ipynb#ch0000012vscode-remote?line=7'>8</a>\u001b[0m             X_test_auto, X_test_auto,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/e/workspace/python/mnist-model/mnist_notebook.ipynb#ch0000012vscode-remote?line=8'>9</a>\u001b[0m             epochs\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/e/workspace/python/mnist-model/mnist_notebook.ipynb#ch0000012vscode-remote?line=9'>10</a>\u001b[0m             batch_size\u001b[39m=\u001b[39m\u001b[39m60\u001b[39m)\n",
      "File \u001b[0;32m/mnt/e/workspace/python/mnist-model/train.py:21\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, model, optim, criterion)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m model\n\u001b[1;32m     20\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptim \u001b[39m=\u001b[39m optim\n\u001b[0;32m---> 21\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss \u001b[39m=\u001b[39m loss \n\u001b[1;32m     22\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_optim_net_aligned()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'loss' is not defined"
     ]
    }
   ],
   "source": [
    "model = Autoencoder(hidden_dim=28)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "trainer = Trainer(model, optimizer, criterion)\n",
    "\n",
    "trainer.fit(X_train_auto, X_train_auto,\n",
    "            X_test_auto, X_test_auto,\n",
    "            epochs=1,\n",
    "            batch_size=60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
